{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extract.ipynb",
      "provenance": [],
      "mount_file_id": "1Ho1dVrdTdbYfzH_vzepeXwvn_VmY8W15",
      "authorship_tag": "ABX9TyNXzTLduqFg5c/P9X6qZZH4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntabanarachel/tech-stack-with-MySQL-DBT-Airflow-and-Spark/blob/main/extraction/extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnIEZOLJsY0q"
      },
      "source": [
        "Load sample data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF1qKc4O15Hj"
      },
      "source": [
        " we  used apache spark to load richard csv "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlrqyRSFsgQQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpZXIHljhPFF"
      },
      "source": [
        "# Use the Spark CSV datasource with options specifying:\n",
        "# - First line of file is a header\n",
        "# - Automatically infer the schema of the data\n",
        "'%python'\n",
        "data = spark.read.csv(\"/content/richards.csv\", header=\"true\", inferSchema=\"true\")\n",
        "data.cache() # Cache data for faster reuse\n",
        "data = data.dropna() # drop rows with missing values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icptafOPiAWW",
        "outputId": "f0b06c3b-8723-40a4-cc61-260a134969c3"
      },
      "source": [
        "!pip  install spark\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spark\n",
            "  Downloading spark-0.2.1.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 30 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 62 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: spark\n",
            "  Building wheel for spark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spark: filename=spark-0.2.1-py3-none-any.whl size=58761 sha256=9ad8b36d913275b0d68e9f521ccf5a577e661bac8ea2203de85b67f2de772174\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/0e/f1/164619f9920fb447d294afaae11a7715bd442ded7225953d72\n",
            "Successfully built spark\n",
            "Installing collected packages: spark\n",
            "Successfully installed spark-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgiNgcZqitGQ",
        "outputId": "e55aaed2-52f7-40cc-9399-bc54322c9553"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 70 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 64.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=6987f9f3487ac4b78e4a4b0fd83024878eb1beb6a1bb87856957c3e2fdc48388\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6IsP_lIilgh"
      },
      "source": [
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "sc = SparkContext.getOrCreate()\n",
        "spark = SparkSession(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRTm9nFCiAlC",
        "outputId": "474ef4be-b1f7-4fad-f5da-f2f4e695bf35"
      },
      "source": [
        "'%python'\n",
        "data.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(flow1=1, occupancy1=0.0056, flow2=3, occupancy2=0.02, flow3=0, occupancy3=0.0, totalflow=4, weekday=4, hour=0, minute=0, second=0),\n",
              " Row(flow1=1, occupancy1=0.0044, flow2=1, occupancy2=0.0056, flow3=2, occupancy3=0.0111, totalflow=4, weekday=4, hour=0, minute=0, second=30),\n",
              " Row(flow1=2, occupancy1=0.0111, flow2=5, occupancy2=0.0278, flow3=1, occupancy3=0.0111, totalflow=8, weekday=4, hour=0, minute=1, second=0),\n",
              " Row(flow1=0, occupancy1=0.0, flow2=2, occupancy2=0.01, flow3=0, occupancy3=0.0, totalflow=2, weekday=4, hour=0, minute=1, second=30),\n",
              " Row(flow1=0, occupancy1=0.0, flow2=2, occupancy2=0.01, flow3=2, occupancy3=0.0178, totalflow=4, weekday=4, hour=0, minute=2, second=0),\n",
              " Row(flow1=0, occupancy1=0.0, flow2=1, occupancy2=0.0056, flow3=0, occupancy3=0.0, totalflow=1, weekday=4, hour=0, minute=2, second=30),\n",
              " Row(flow1=1, occupancy1=0.0044, flow2=4, occupancy2=0.0222, flow3=2, occupancy3=0.01, totalflow=7, weekday=4, hour=0, minute=3, second=0),\n",
              " Row(flow1=0, occupancy1=0.0, flow2=0, occupancy2=0.0, flow3=0, occupancy3=0.0, totalflow=0, weekday=4, hour=0, minute=3, second=30),\n",
              " Row(flow1=3, occupancy1=0.0178, flow2=4, occupancy2=0.0233, flow3=2, occupancy3=0.0167, totalflow=9, weekday=4, hour=0, minute=4, second=0),\n",
              " Row(flow1=1, occupancy1=0.0044, flow2=5, occupancy2=0.03, flow3=1, occupancy3=0.0056, totalflow=7, weekday=4, hour=0, minute=4, second=30)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "wkhOAGidrNhj",
        "outputId": "9ed1b641-d721-4a39-8501-40d2e3dcd3e0"
      },
      "source": [
        "'%python'\n",
        "display(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[flow1: int, occupancy1: double, flow2: int, occupancy2: double, flow3: int, occupancy3: double, totalflow: int, weekday: int, hour: int, minute: int, second: int]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9J4QJBKsRo_"
      },
      "source": [
        "Run SQL queries\n",
        "Before you can issue SQL queries, you must save your data DataFrame as a temporary table:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AQYYUvdsWxK"
      },
      "source": [
        "'%python'\n",
        "# Register table so it is accessible via SQL Context\n",
        "data.createOrReplaceTempView(\"richards\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pFaIZ5VwnRg"
      },
      "source": [
        "Visualize the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Ezrv2KwpUg"
      },
      "source": [
        "select `year`, `occupancy1` from richards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdnTvlmpteSa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q_pkPlFtD0s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM9TN7DfsLJV"
      },
      "source": [
        "*italicized text*"
      ]
    }
  ]
}