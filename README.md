# tech-stack-with-MySQL-DBT-Airflow-and-Spark
Data Engineering_Data warehouse

Data Engineering: Data warehouse tech stack with MySQL, DBT, Airflow, and Spark




<b>Business Need</b>

You and your colleagues have joined to create an AI startup that deploys sensors to businesses, collects data from all activities in a business - from peopleâ€™s interaction to the smart appliances installed in the company to reading environmental and other relevant information. Your startup is responsible to install all the required sensors, receive a stream of data from all sensors, and analyse the data to provide key insights to the business. The objective of your contract with the client is to reduce the cost of running the client facility as well as to increase the livability and productivity of workers.

In this challenge   I am tasked to create a scalable data warehouse tech-stack that will help you provide the AI service to the client.
By the end of this project, I should produce a tool that can be used as a basis for the data warehouse needs of MY startup.

<b>Expected Outcomes</b>

Skills:

Create and maintain Airflow DAGs
Work with Apache Airflow, dbt, redash  and a DWH

Apply ELT techniques to DWH

Build data pipelines and orchestration workflows


Knowledge:

Enterprise-grade data engineering 

using Apache and Databricks tools
